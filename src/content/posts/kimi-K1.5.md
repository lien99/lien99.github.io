---
title: kimi-K1.5的一些理解
published: 2025-04-20
draft: false
---

Kimi k1.5 的开发包括几个阶段：

```
1.预训练
2.基础监督微调（vanilla supervised fine-tuning, SFT）
3.长链思维监督微调（long-CoT supervised fine-tuning）
4.强化学习（RL）
```



### RL prompt

一个精心构建的提示集不仅能引导模型进行稳健的推理，还能减轻奖励欺骗（reward hacking）和对表面模式过拟合的风险。

定义了高质量RL prompt具备的三个特性

```
1. 多样性覆盖：提示应涵盖广泛的学科领域，如 STEM（科学、技术、工程、数学）、编码和一般推理，以增强模型的适应性并确保在不同领域的广泛适用性。
2. 平衡的难度：提示集应包含难度分布均衡的简单、中等和困难问题，以促进逐步学习，并防止对特定复杂程度的过拟合。
3. 准确的可评估性：提示应允许验证器进行客观和可靠的评估，确保模型的性能是基于正确的推理来衡量，而不是基于表面模式或随机猜测。
```

为了得到高质量的数据，做了以下尝试

```
针对多样性：
	1. 开发了一个automatic filters选择需要推理并切易于评估的问题。
	2. 开发了一个tagging system将所有的prompt按领域和学科（domain and discipline）进行分类。
	
针对prompt难度
	对于每个prompt，一个经过 SFT 训练的模型使用相对高的temperature生成十次答案，然后计算通过率，将其作为prompt难度的代理指标——通过率越低，难度越高。这种方法使得难度评估与模型的内在能力相一致，使其对 RL 训练非常有效。
	
针对可评估性
	发现问题：假阳性验证——即模型通过不正确的推理过程达到了正确答案
	解决思路：
		1. 排除了容易出现此类错误的问题，例如选择题、判断题和基于证明的问题
		2. 对于一般的问答任务，提出了一种简单但有效的方法来识别和移除容易被欺骗的prompt。具体来说，提示一个模型在没有任何链思维（CoT）推理步骤的情况下猜测可能的答案。如果在 N 次尝试内模型预测出正确答案，则该提示被认为太容易被欺骗并被移除。论文中将N设为8。
```



### Long-CoT SFT

利用上述RL promt生成少量但高质量的数据集，通过这些数据集旨在让模型学到类人类推理的关键认知过程

```
1. planning：模型在执行前系统地概述步骤
2. evaluation：对中间步骤的批判性评估
3. reflecti：使模型能够重新考虑和完善其方法
4. exploration：鼓励考虑替代解决方案
```

>By performing a lightweight SFT on this warm-up dataset, we effectively prime the model to internalize these reasoning strategies.





## Appendix - Pretraining

### Language Data

#### 文本数据

针对文本数据开发了一个多维度的质量过滤框架

```
1. 基于规则的过滤：实施了特定领域的启发式规则，以移除有问题的内容，包括重复内容、机器翻译文本和低质量的网络抓取数据。还过滤掉包含过多特殊字符、异常格式或垃圾邮件模式的文档
2. 基于 FastText 的分类：我们训练了专门的 FastText 模型，根据语言特征和语义连贯性识别内容质量。有助于识别语言流畅、语法结构正确的文档。
3. Embedding-based相似性分析：使用document embeddings，计算文档级别的相似性得分，以识别和移除近似重复项，方便维持训练语料库的多样性
4. 基于 LLM 的质量评估：利用 LLMs 根据连贯性、信息量和潜在教育价值对文档进行评分
```

每个文档的最终质量得分是这些单独得分的组合计算得出，并且实现了动态采样率，其中高质量文档在训练期间被上采样，而低质量文档被下采样

#### Code data

代码数据主要有两类

```
1. 源自代码文件的纯代码数据，遵循了 BigCode（引用 R. Li 等人 2023 年；Lozhkov 等人 2024 年的工作）的方法，并对数据集进行了全面的预处理。
	1）剔除了杂项语言，并应用了基于规则的清洗程序来提高数据质量。
	2）通过strategic sampling techniques解决了语言不平衡问题。具体来说，像 JSON、YAML 和 YACC 这样的标记语言被下采样，而包括 Python、C、C++、Java 和 Go 在内的 32 种主要编程语言被上采样。

2. 对于来源于各种数据源的图文结合数据，使用基于嵌入的方法来召回高质量数据。
```

####Math & Reasoning data

数学预训练数据主要从公共互联网资源收集的网络文本和 PDF 文档中获取。

```
发现问题：通用领域文本提取、数据清洗过程和 OCR 模型在数学领域表现出高假阴性率。

解决策略：
	1. 专门为数学内容开发了专门的数据清洗程序和 OCR 模型，旨在最大限度地提高数学数据的召回率。
	2. 实施了一个两阶段的数据清洗过程:
		1)使用 FastText 模型进行初步清洗，以移除大多数不相关的数据。
		2)利用经过微调的语言模型对剩余数据进行进一步清洗，从而获得高质量的数学数据。
```

#### Knowledge data

知识库主要包括学术习题、教科书、研究论文和其他一般性教育文献。这些材料中有很大一部分是通过 OCR 处理数字化的，为此我们开发了专门针对学术内容优化的专有模型，特别是用于处理数学公式和特殊符号。

利用内部语言模型对文档进行多维标签标注，主要有如下几个维度

```
1. OCR 质量指标，用于评估识别准确性
2. 教育价值指标，衡量教学相关性
3. 文档类型分类（例如，习题、理论材料）
```

基于上述多维度标注，实施了一个复杂的过滤和采样流程

```
1. 通过 OCR 质量阈值进行过滤，OCR 质量评估框架特别关注检测和过滤掉常见的 OCR 伪影，特别是通常表明识别失败的重复文本模式
2. 评分系统仔细评估每个文档的教育价值，具有高教学相关性和知识深度的文档得到优先处理，同时在理论深度和教学清晰度之间保持平衡。
3. 对不同类型的文档进行制定采样策略。对文档进行独立评估，以识别对模型知识获取能力贡献最显著的文档子集，这些高价值子集在最终的训练语料库中被上采样。同时按适当比例保留了其他文档类型。
```



### Multimodal data

#### Caption data

```
作用：
	1. 提供了基本的模态对齐能力
	2. 提供了广泛的世界知识

过滤和清洗：
	1. 在整个训练过程中，严格限制合成图像描述数据的比例，以减轻由于真实世界知识不足而导致的幻觉风险。
	2. 对于一般的图像描述数据，遵循严格的质量控制流程，避免重复并保持高图文相关性
	3. 在预训练期间，还改变图像分辨率，以确保在处理高分辨率和低分辨率图像时都能保持有效
```



#### Image-text interleaving data

```
作用：
	1. 图文交错数据可以增强多图像理解能力
	2. 图文交错数据总是为给定图像提供详细的知识
	3. 图文交错数据还可以获得更长的多模态上下文学习能力
	4. 【重要】图文交错数据有助于保持模型的语言能力
	
发现合成图文交错数据有利于多模态 LLM 在保留文本知识方面的性能

过滤和清洗：
	1. 标准的过滤、去重和其他质量控制流程
	2. 整合了一个数据重新排序程序，以保持所有图像和文本的正确顺序
```

#### OCR data

```
来源：
	包括开源数据集和内部数据集，涵盖了干净图像和增强图像。其中大量内部 OCR 数据集，涵盖多语言文本、密集文本布局、基于网页的内容和手写样本。

应用了广泛的数据增强技术——例如旋转、失真、颜色调整和添加噪声——以增强模型的鲁棒性
```

#### Knowledge data

```
侧重于从不同来源汇集全面的人类知识库，以进一步增强模型的能力，遵循标准化的分类体系，以平衡各种类别的内容，确保数据来源的多样性
```



#### QA data

```
1. 纳入了严格的学术数据集，涵盖了基础概念理解、表格/图表问答、网络代理任务和一般问答等任务
2. 汇编了大量内部问答数据（we compiled a large amount of in-house QA data to further enhance the model’s capabilities）

为了保持平衡的难度和多样性，我们对一般问答数据集应用了评分模型和细致的人工分类，从而提高了整体性能
```



### 模型结构

闭源模型

![image-20250424124042136](https://typora-1305283193.cos.ap-guangzhou.myqcloud.com/typora/image-20250424124042136.png)



### Training Stages

Kimi k1.5 模型分三个阶段进行训练

```
1. vision-language pretraining stage
2. vision-language cooldown stage
3. long-context activation stage
```

#### pretraining

训练步骤

```
1. 首先仅在语言数据上进行训练
2. 逐渐向模型引入图文交错的视觉-语言数据，使其获得多模态能力。 visual tower最初独立训练，不更新语言模型参数，然后解除冻结（unfreeze）语言模型层，最终将视觉-文本数据的比例增加到 30%
（最终的数据混合比例及其各自的权重是通过在较小模型上进行的消融研究确定的）
```

#### cooldown

冷启动阶段

```
发现：
	在冷启动阶段整合合成数据能够显著提升性能，特别是在数学推理、基于知识的任务和代码生成方面

数据来源：
	冷启动数据集的英语和中文部分来自预训练语料库的high-fidelity subsets

对于数学、知识和代码领域，采用混合方法：
	利用选定的预训练子集，同时用合成生成的内容对其进行扩充。具体来说，我们利用现有的数学、知识和代码语料库作为源材料，通过专有的语言模型生成问答对，并实施拒绝采样技术来保持质量标准
```



#### action

```
数据来源：
	上采样的长上下文冷启动数据

在长上下文训练期间使用了 40% 的全注意力数据和 60% 的部分注意力数据：
	1. 全注意力数据部分来自高质量的自然数据，部分来自合成的长上下文问答和摘要数据（partly from high-quality natural data and partly from synthetic long context Q&A and summary data）
	2. 部分注意力数据来自对冷启动数据的均匀采样（uniform sampling of cooldown data）
	
旋转位置嵌入（RoPE）频率设置为 1,000,000。在此阶段，通过将最大序列长度从 4,096 逐渐增加到 32,768，最终增加到 131,072，逐步扩展了长度激活训练。
```



